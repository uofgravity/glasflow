{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of using conditional flows with `glasflow` using a dataset from `sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glasflow import RealNVP\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "torch.manual_seed(1451)\n",
    "np.random.seed(1451)\n",
    "sns.set_context(\"notebook\")\n",
    "sns.set_palette(\"colorblind\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `make_blobs` to make a set of Gaussian blobs corresponding to different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = make_blobs(\n",
    "    n_samples=10000,\n",
    "    n_features=2,\n",
    "    centers=4,\n",
    "    cluster_std=[1.7, 5.0, 3.1, 0.2],\n",
    "    random_state=314159,\n",
    ")\n",
    "classes = np.unique(labels)\n",
    "print(f\"Classes are: {classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(dpi=100)\n",
    "markers = [\".\", \"x\", \"+\", \"^\"]\n",
    "for c, m in zip(classes, markers):\n",
    "    idx = labels == c\n",
    "    plt.scatter(\n",
    "        data[idx, 0], data[idx, 1], label=f\"Class {c}\", marker=m, alpha=0.8\n",
    "    )\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "flow = RealNVP(\n",
    "    n_inputs=2,\n",
    "    n_transforms=4,\n",
    "    n_conditional_inputs=1,\n",
    "    n_neurons=32,\n",
    "    batch_norm_between_transforms=True,\n",
    ")\n",
    "flow.to(device)\n",
    "print(f\"Created flow and sent to {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = torch.optim.Adam(flow.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "x_train, x_val, y_train, y_val = train_test_split(data, labels[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the data using dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tensor = torch.from_numpy(x_train.astype(np.float32))\n",
    "y_train_tensor = torch.from_numpy(y_train.astype(np.float32))\n",
    "train_dataset = torch.utils.data.TensorDataset(x_train_tensor, y_train_tensor)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "x_val_tensor = torch.from_numpy(x_val.astype(np.float32))\n",
    "y_val_tensor = torch.from_numpy(y_val.astype(np.float32))\n",
    "val_dataset = torch.utils.data.TensorDataset(x_val_tensor, y_val_tensor)\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "loss = dict(train=[], val=[])\n",
    "\n",
    "for i in range(epochs):\n",
    "    flow.train()\n",
    "    train_loss = 0.0\n",
    "    for batch in train_loader:\n",
    "        x, y = batch\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        optimiser.zero_grad()\n",
    "        _loss = -flow.log_prob(x, conditional=y).mean()\n",
    "        _loss.backward()\n",
    "        optimiser.step()\n",
    "        train_loss += _loss.item()\n",
    "    loss[\"train\"].append(train_loss / len(train_loader))\n",
    "\n",
    "    flow.eval()\n",
    "    val_loss = 0.0\n",
    "    for batch in val_loader:\n",
    "        x, y = batch\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        with torch.no_grad():\n",
    "            _loss = -flow.log_prob(x, conditional=y).mean().item()\n",
    "        val_loss += _loss\n",
    "    loss[\"val\"].append(val_loss / len(val_loader))\n",
    "    if not i % 10:\n",
    "        print(\n",
    "            f\"Epoch {i} - train: {loss['train'][-1]:.3f}, val: {loss['val'][-1]:.3f}\"\n",
    "        )\n",
    "\n",
    "flow.eval()\n",
    "print(\"Finished training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss[\"train\"], label=\"Train\")\n",
    "plt.plot(loss[\"val\"], label=\"Val.\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10000\n",
    "conditional = torch.from_numpy(\n",
    "    np.random.choice(4, size=(n, 1)).astype(np.float32)\n",
    ").to(device)\n",
    "with torch.no_grad():\n",
    "    samples = flow.sample(n, conditional=conditional)\n",
    "samples = samples.cpu().numpy()\n",
    "conditional = conditional.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the figure below we can see that the flow probably requires a bit more training but it does show how the flow can learn each distribution using the conditional inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(\n",
    "    1, 2, sharex=True, sharey=True, figsize=(10, 5), dpi=100\n",
    ")\n",
    "markers = [\".\", \"x\", \"+\", \"^\"]\n",
    "for c, m in zip(classes, markers):\n",
    "    idx = labels == c\n",
    "    ax[0].scatter(\n",
    "        data[idx, 0], data[idx, 1], label=f\"Class {c}\", marker=m, alpha=0.5\n",
    "    )\n",
    "\n",
    "    idx = conditional[:, 0] == c\n",
    "    ax[1].scatter(\n",
    "        samples[idx, 0],\n",
    "        samples[idx, 1],\n",
    "        label=f\"Class {c}\",\n",
    "        marker=m,\n",
    "        alpha=0.5,\n",
    "    )\n",
    "ax[0].set_title(\"Data\")\n",
    "ax[1].set_title(\"Samples from flow\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('test-example')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "3517700c92508b2e59eb9f265f5f8465660b244c7bbb91180936f922ef327d4b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
